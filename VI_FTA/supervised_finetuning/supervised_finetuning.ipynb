{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414b53281ead4e088901335b9d7b7180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ed842bc24744778a0e639613838c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/233k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da197ce5b2d4b68aae8fb9b6c67cd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/105k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322126e928394ac6854cc1daf9ed5f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/28.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbea0d84abd149248b4a64991cd90868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3257 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb95e7f83991492e9f207a5fa15c4319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e0bd5efb3343f78b97bbae55b9f511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/374 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset overview: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 3257\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1421\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 374\n",
      "    })\n",
      "})\n",
      "Dataset features: dict_keys(['text', 'label'])\n",
      "Example row: {'text': \"My roommate: it's okay that we can't spell because we have autocorrect. #terrible #firstworldprobs\", 'label': 0}\n",
      "\n",
      "Number of classes: 4\n",
      "Label distribution for \"train\" split: Counter({0: 1400, 3: 855, 1: 708, 2: 294})\n",
      "Label distribution for \"test\" split: Counter({0: 558, 3: 382, 1: 358, 2: 123})\n",
      "Label distribution for \"validation\" split: Counter({0: 160, 1: 97, 3: 89, 2: 28})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import datasets\n",
    "\n",
    "# \"dictionary\" mapping name of split (train/validation/test) to\n",
    "# a Dataset for that split.\n",
    "dataset_dict = datasets.load_dataset(\"tweet_eval\", \"emotion\")\n",
    "\n",
    "example_row = dataset_dict[\"train\"][1]\n",
    "print(\"Dataset overview:\", dataset_dict)\n",
    "print(\"Dataset features:\", example_row.keys())\n",
    "print(\"Example row:\", example_row)\n",
    "print()\n",
    "\n",
    "label_distribution: dict[str, Counter] = {\n",
    "    split_name: Counter([row[\"label\"] for row in split_dataset])\n",
    "    for split_name, split_dataset in dataset_dict.items()\n",
    "}\n",
    "num_label_classes = len(label_distribution[\"train\"].keys())\n",
    "print(\"Number of classes:\", num_label_classes)\n",
    "for split_name, split_label_distribution in label_distribution.items():\n",
    "    print(f'Label distribution for \"{split_name}\" split:', split_label_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model and tokenizer from /projects/fta_bootcamp/downloads/opt-350m/\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "# Use shared copy of the model if running this example on the Vector cluster.\n",
    "# Otherwise, download model from HuggingFace.\n",
    "base_model_repo = \"facebook/opt-350m\"\n",
    "local_model_path = \"/projects/fta_bootcamp/downloads/opt-350m/\"\n",
    "if os.path.isdir(local_model_path):\n",
    "    base_model_repo = local_model_path\n",
    "\n",
    "print(f\"Loading pretrained model and tokenizer from {base_model_repo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of examples presented to the model in a given step.\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build training and evaluation batches\n",
    "\n",
    "Combining more than one rows of data into a \"batch\" helps increase throughput on GPUs, both for training and for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "\n",
    "\n",
    "def build_data_batches(\n",
    "    dataset_rows: list[dict[str, Any]],\n",
    "    batch_size: int,\n",
    "    tokenizer: PreTrainedTokenizerBase,\n",
    "    text_column_name: str = \"text\",\n",
    "    label_column_name: str = \"label\",\n",
    ") -> list[dict[str, torch.TensorType]]:\n",
    "    \"\"\"Build batches out of a list of examples.\n",
    "\n",
    "    For simplicity, if some trailing examples don't fit in a batch,\n",
    "    those examples would not be included in the output.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "        dataset_rows: List of dictionaries, one for each row of the dataset.\n",
    "        batch_size: Number of examples to include in each batch.\n",
    "        tokenizer: HuggingFace Tokenizer\n",
    "        text_column_name: name of text column in dataset_rows\n",
    "        label_column_name: name of label column in dataset_rows\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        list of dictionaries, one for each batch.\n",
    "        Each dictionary consists of:\n",
    "        - input_ids: integer tensors of shape (batch_size, max_width)\n",
    "        - attention_mask: boolean tensor of same shape as input_ids,\n",
    "            highlighting which of the items in the input_ids tensor are paddings\n",
    "            (not actual words, but added for performance reasons)\n",
    "        - labels: tensor of shape (batch_size,) one per row.\n",
    "\n",
    "        Values of the dictionary are tensors.\n",
    "\n",
    "    \"\"\"\n",
    "    # list of batches. Text would be replaced with tokenization tensors,\n",
    "    # while labels would be stored as PyTorch Tensors (lists)\n",
    "    output: list[dict[str, torch.TensorType]] = []\n",
    "\n",
    "    # Buffer for a batch of dataset rows, not yet tokenized.\n",
    "    text_buffer: list[str] = []\n",
    "    label_buffer: list[Any] = []\n",
    "    num_examples_in_buffer = 0\n",
    "\n",
    "    for row in tqdm(dataset_rows):\n",
    "        # TODO: Add text from the dataset \"row\" to the text buffer.\n",
    "        # Recall that \"row\" is a dictionary mapping dataset feature\n",
    "        # to value. The name of the text feature is in the \"text_column_name\"\n",
    "        # variable.\n",
    "        #\n",
    "        # Hint:\n",
    "        #   text_buffer.append(...)\n",
    "        text_buffer.append(row[text_column_name])\n",
    "        label_buffer.append(row[label_column_name])\n",
    "\n",
    "        num_examples_in_buffer += 1\n",
    "\n",
    "        # Group (batch_size) raw dataset rows into one processed batch of tensors.\n",
    "        if num_examples_in_buffer == batch_size:\n",
    "            print(len(text_buffer))\n",
    "            print(len(label_buffer))\n",
    "            assert len(text_buffer) == batch_size\n",
    "            assert len(label_buffer) == batch_size\n",
    "\n",
    "            output.append(\n",
    "                {\n",
    "                    **tokenizer(text_buffer, return_tensors=\"pt\", padding=True),\n",
    "                    \"labels\": torch.Tensor(label_buffer).type(torch.long),\n",
    "                },\n",
    "            )\n",
    "            text_buffer = []\n",
    "            label_buffer = []\n",
    "            num_examples_in_buffer = 0\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df77224526e84ac38bc96fa3f29771e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c883c217a6a841f4b384c2548c1bb3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853778175e0d4c1eb9619c5ee357611f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "processed batches: {'train': 407, 'test': 177, 'validation': 46}\n"
     ]
    }
   ],
   "source": [
    "processed_dataset_dict = {\n",
    "    split_name: build_data_batches(dataset_split, BATCH_SIZE, tokenizer)\n",
    "    for split_name, dataset_split in dataset_dict.items()\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"processed batches:\",\n",
    "    {split_name: len(split) for split_name, split in processed_dataset_dict.items()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example batch: {'input_ids': torch.Size([8, 33]), 'attention_mask': torch.Size([8, 33]), 'labels': torch.Size([8])}\n"
     ]
    }
   ],
   "source": [
    "example_batch = processed_dataset_dict[\"train\"][0]\n",
    "print(\"Example batch:\", {k: v.shape for k, v in example_batch.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: torch.nn.Module, processed_dataset: list[dict[str, torch.Tensor]],\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Evaluate model on given dataset.\n",
    "\n",
    "    See above for a demo of the inner working of this function.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "        model: transformer classifier model to evaluate.\n",
    "        processed_dataset: list of pre-processed (tokenized) batches.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        (cross-entropy loss, accuracy)\n",
    "\n",
    "    \"\"\"\n",
    "    criteria = torch.nn.CrossEntropyLoss()\n",
    "    loss_values: list[torch.Tensor] = []\n",
    "    accuracy_values: list[torch.Tensor] = []\n",
    "\n",
    "    with tqdm(total=len(processed_dataset)) as progress_bar:\n",
    "        for batch_cpu in processed_dataset:\n",
    "            batch = {k: v.to(model.device) for k, v in batch_cpu.items()}\n",
    "            logits = model(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "            ).logits\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            loss = criteria(logits, labels).item()\n",
    "            loss_values.append(loss)\n",
    "\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            accuracy = torch.mean((predictions == labels).type(torch.float)).item()\n",
    "            accuracy_values.append(accuracy)\n",
    "\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        avg_loss = sum(loss_values) / len(loss_values)\n",
    "        avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n",
    "\n",
    "        progress_bar.set_description(\n",
    "            f\"Eval loss {avg_loss:.3f} acc {avg_accuracy * 100:.1f}%\",\n",
    "        )\n",
    "\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding a new classification layer on top of pretrained weights- \n",
      "you will see a reminder from HuggingFace that \"You should probably TRAIN this model\":\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at /projects/fta_bootcamp/downloads/opt-350m/ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8ca5c613884e8e939cb6888bf7bd3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755b683008d442bda61f2b0d4afee22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b53f96433a94b23833197ef404a752e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6570216ba5484043b2d92b384f4b0c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e400d86f4d46e9a027cc9fa8360c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8da8bbcafa4a859f61188ea86debcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3e4900d6984a33bd57e22f94a73314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2a66478b2847cd878642176908e377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a089cf7388234a4f9301bee79d63ceec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5999eb63b0734a50ae723b653876f856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129777045326452b87c179118cdd69d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "train_data = processed_dataset_dict[\"train\"]\n",
    "validation_data = processed_dataset_dict[\"validation\"]\n",
    "\n",
    "print(\n",
    "    \"Adding a new classification layer on top of pretrained weights- \\n\"\n",
    "    \"you will see a reminder from HuggingFace that \"\n",
    "    '\"You should probably TRAIN this model\":',\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model_repo, num_labels=num_label_classes,\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "criteria = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Train for 100 steps\n",
    "for train_step, batch_cpu in enumerate(tqdm(processed_dataset_dict[\"train\"][:100])):\n",
    "    # evaluate model on validation set every 10 steps\n",
    "    if train_step % 10 == 0:\n",
    "        model.eval()  # turn off back-propagation to evaluate faster\n",
    "        eval_accuracy, eval_loss = evaluate_model(model, validation_data)\n",
    "        model.train()  # turn back-propagation back on\n",
    "\n",
    "    # Send batch to accelerator device\n",
    "    batch = {k: v.to(device) for k, v in batch_cpu.items()}\n",
    "    model_output = model(\n",
    "        input_ids=batch[\"input_ids\"],\n",
    "        attention_mask=batch[\"attention_mask\"],\n",
    "    )\n",
    "\n",
    "    training_loss = criteria(model_output.logits, batch[\"labels\"])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    training_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de512cdb3d504d648cff53aec05b059a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation loss: 0.73; accuracy 73.6%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_loss, eval_accuracy = evaluate_model(model, validation_data)\n",
    "\n",
    "print(f\"Final validation loss: {eval_loss:.2f}; accuracy {eval_accuracy * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: tensor([1, 0, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# labels for tweet_eval emotion:\n",
    "# 0: anger; 1: joy; 2: optimism; 3: sadness\n",
    "example_input = [\"Good book!\", \"Bad book!\", \"It is raining all day!\"]\n",
    "example_input_encoded = tokenizer(example_input, return_tensors=\"pt\", padding=True)\n",
    "model_output = model(\n",
    "    input_ids=example_input_encoded[\"input_ids\"].to(device),\n",
    "    attention_mask=example_input_encoded[\"attention_mask\"].to(device),\n",
    ")\n",
    "\n",
    "predictions = torch.argmax(model_output.logits, dim=-1)\n",
    "print(\"predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer Integration\n",
    "\n",
    "HuggingFace provides abstractions for common use cases- including sequence classification. \n",
    "\n",
    "Reproduced from [transformers/en/tasks/sequence_classification](https://huggingface.co/docs/transformers/en/tasks/sequence_classification) with simplifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding a new classification layer on top of pretrained weights- \n",
      "you will see a reminder from HuggingFace that \"You should probably TRAIN this model\":\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at /projects/fta_bootcamp/downloads/opt-350m/ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2949375043fa4e9eb495991a08365421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3257 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222ebba680b94c018fb1b3d34b8d39c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c25bb241ad4773bf987dc2bfd3a64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/374 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c36d65d729466c8df1923258f063fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 01:01, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.547266</td>\n",
       "      <td>0.419786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.367585</td>\n",
       "      <td>0.483957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.283064</td>\n",
       "      <td>0.508021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.277318</td>\n",
       "      <td>0.505348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.140942</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.095202</td>\n",
       "      <td>0.556150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.019637</td>\n",
       "      <td>0.574866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.931600</td>\n",
       "      <td>0.622995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.910769</td>\n",
       "      <td>0.649733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.915570</td>\n",
       "      <td>0.644385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(374,)\n",
      "(374,)\n",
      "(374,)\n",
      "(374,)\n",
      "(374,)\n",
      "(374,)\n",
      "(374,)\n",
      "(374,)\n",
      "(374,)\n",
      "(374,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=102, training_loss=1.2115893644445084, metrics={'train_runtime': 61.4227, 'train_samples_per_second': 13.256, 'train_steps_per_second': 1.661, 'total_flos': 55682334720000.0, 'train_loss': 1.2115893644445084, 'epoch': 0.25})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "device = torch.device(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "print(\n",
    "    \"Adding a new classification layer on top of pretrained weights- \\n\"\n",
    "    \"you will see a reminder from HuggingFace that \"\n",
    "    '\"You should probably TRAIN this model\":',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_repo)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model_repo, num_labels=num_label_classes,\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "tokenized_dataset = dataset_dict.map(\n",
    "    lambda examples: tokenizer(\n",
    "        examples[\"text\"]\n",
    "        # TODO: The input to tokenizer() should be a list of text (list[str]).\n",
    "        # each `examples` is a dict[str, list[Any]], mapping the name\n",
    "        # of the column of the dataset to a list of values from that column.\n",
    "        # Which column should you tokenize?\n",
    "        #\n",
    "        # hint: `examples[\"name_of_column\"]`\n",
    "    ),\n",
    "    batched=True,\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # TODO: How would you obtain the predictions from the logits tensor?\n",
    "    # Hint: using numpy, take argmax over the dimension (-1).\n",
    "    #\n",
    "    # If \"logits\" is a 2D array of shape (batch, num_choices),\n",
    "    # Your \"predictions\" should be a 1D array of shape (batch,)\n",
    "    #\n",
    "    # predictions = ...\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    print(predictions.shape)\n",
    "    assert isinstance(predictions, (np.ndarray, torch.Tensor))\n",
    "    assert predictions.shape == (logits.shape[0],)\n",
    "\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../../scratch/supervised_finetuning/checkpoints\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=0.25,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb5b076a7904e808b25c7612eb7d6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation loss: 0.92; accuracy 64.4%\n",
      "predictions: tensor([1, 0, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = trainer.model\n",
    "model.eval()\n",
    "eval_loss, eval_accuracy = evaluate_model(model, validation_data)\n",
    "\n",
    "print(f\"Final validation loss: {eval_loss:.2f}; accuracy {eval_accuracy * 100:.1f}%\")\n",
    "\n",
    "# labels for tweet_eval emotion:\n",
    "# 0: anger; 1: joy; 2: optimism; 3: sadness\n",
    "example_input = [\"Good book!\", \"Bad book!\", \"It is raining all day!\"]\n",
    "example_input_encoded = tokenizer(example_input, return_tensors=\"pt\", padding=True)\n",
    "model_output = model(\n",
    "    input_ids=example_input_encoded[\"input_ids\"].to(device),\n",
    "    attention_mask=example_input_encoded[\"attention_mask\"].to(device),\n",
    ")\n",
    "\n",
    "predictions = torch.argmax(model_output.logits, dim=-1)\n",
    "print(\"predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune_demo",
   "language": "python",
   "name": "finetune_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4247c1",
   "metadata": {},
   "source": [
    "## Topic discovery: yelp review\n",
    "\n",
    "This notebook shows how to load a huge LLM and perform inference using ```accelerate```. See ```0_guide``` for detail and reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8454322b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\cygdrive\\d\\projects\\LLM_py38\\venv\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "D:\\cygdrive\\d\\projects\\LLM_py38\\venv\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "D:\\cygdrive\\d\\projects\\LLM_py38\\venv\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# from huggingface_hub import hf_hub_download \n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import evaluate\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM\n",
    "from transformers import MistralForCausalLM\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from peft import PeftConfig, PeftModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from huggingface_hub import notebook_login\n",
    "from accelerate import init_empty_weights, load_checkpoint_and_dispatch, infer_auto_device_map, dispatch_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dc548bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.35.2\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e33f758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu118\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "463d6fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:41:10_Pacific_Daylight_Time_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604e92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_repo_dir = 'D:/projects/LLM'\n",
    "cache_dir = '/cygdrive/d/projects/LLM/.cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "os.environ['HF_HOME'] = cache_dir + '/huggingface'\n",
    "os.environ['XDG_CACHE_HOME'] = cache_dir\n",
    "os.environ['HF_DATASETS_CACHE'] = cache_dir\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5cf0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = cache_dir + '/parquet/yelp_polarity' # cache_dir + '/parquet/yelp_review_full-e22176106d6e7534'\n",
    "dataset_name = 'yelp_polarity' # yelp_review_full\n",
    "\n",
    "if not os.path.isdir(dataset_path):\n",
    "    dataset = load_dataset(dataset_name, cache_dir=cache_dir + '/parquet')\n",
    "else:\n",
    "    dataset = load_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30677093",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data_path = cache_dir + '/tokenized_dataset_yelp_polarity_bert'\n",
    "\n",
    "tokenized_datasets = load_from_disk(tokenized_data_path)\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "144f71b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(type(small_train_dataset))\n",
    "print(small_train_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b6621",
   "metadata": {},
   "source": [
    "## Gen AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c92a72da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## T5-3b\n",
    "#model_name = 'google-t5/t5-3b'\n",
    "#model_path = cache_dir + '/models--google-t5--t5-3b/snapshots/bed96aab9ee46012a5046386105ee5fd0ac572f0'\n",
    "\n",
    "# Mistral 7B\n",
    "model_name = 'mistralai/Mistral-7B-v0.1'\n",
    "model_path = cache_dir + '/models--mistralai--Mistral-7B-v0.1/snapshots/26bca36bde8333b5d7f72e9ed20ccda6a618af24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12cca16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371bb7b670f9467aa9a62fac30cdf7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# need this to get token to access a gated model\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d61a773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d85c08fa24e4ffa8876c32fc79980e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\cygdrive\\d\\projects\\LLM_py38\\venv\\lib\\site-packages\\accelerate\\utils\\modeling.py:1363: UserWarning: Current model requires 536879104 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "D:\\cygdrive\\d\\projects\\LLM_py38\\venv\\lib\\site-packages\\accelerate\\utils\\modeling.py:1363: UserWarning: Current model requires 268439552 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_tokenizer = AutoTokenizer.from_pretrained(model_path, \n",
    "                                          cache_dir=cache_dir, \n",
    "                                          local_flies_only=True)\n",
    "\n",
    "# load empty model to save memory\n",
    "with init_empty_weights():\n",
    "    mistral_model = AutoModelForCausalLM.from_pretrained(model_path, \n",
    "                                             cache_dir=cache_dir,\n",
    "                                             local_files_only=True,\n",
    "                                             load_in_8bit=True)\n",
    "    \n",
    "mistral_model = load_checkpoint_and_dispatch(mistral_model, \n",
    "                                             model_path,\n",
    "                                             device_map='auto',\n",
    "                                             offload_folder=None)\n",
    "\n",
    "device_map  = infer_auto_device_map(mistral_model.model)\n",
    "full_model_device_map = {f\"model.{k}\": v for k, v in device_map.items()}\n",
    "full_model_device_map[\"lm_head\"] = 0\n",
    "dispatch_model(mistral_model, device_map=full_model_device_map) # make sure on the same device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35010cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our experience not so great.  We have mortgage as well as basic free checking and savings with Dollar in Squirrel Hill.  Mortgage application process was brutal.  Starting with the advertised rate of 2.85% being suddenly not available when we decided to lock it in; got 3.01%.  Automatic deduction of mortgage payment was required to secure this rate and it came out of the required Dollar checking account on the first business day of the month.  Free checking is free ... until.  Beware of Funds Availability policy.  We deposit a check monthly at the end of the month.  In August, the end of the month was a weekend and Labor Day was on September 1.  So our check did not get deposited until 9/2.  Mortgage payment hit on 9/2. It was paid, but we were charged $36 insufficient funds due solely to Funds Availability Policy.  After doing this first, Dollar then merrily hits us with two more $36 charges on smaller checks that would have cleared had they been processed before the mortgage payment.  Had we NOT been required to submit to automatic deduction of mortgage, according to our monthly statement, we had at least 10 days grace to make the payment, so Dollar\\'s requirements and policies trapped us into this situation.  Moreover, there was over $3000 in the associated savings account that was ignored.  I called to protest, and one of the $36 fees was waived.  Then I was offered the \\\\\"\"deal\\\\\"\" of overdraft protection from the savings account for an annual fee plus a $10 transaction fee should this situation ever arise again.  Needless to say, I declined this deal and transferred the savings to the checking account where it sits until I find another bank and then fire Dollar.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']['text'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1e9df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" \n",
    "Describe the theme of the comment in one word.\n",
    "\n",
    "Comment: {0}\n",
    "Theme: healthcare\n",
    "\n",
    "Comment: {1}\n",
    "Theme: food\n",
    "\n",
    "Comment: {2}\n",
    "Theme: recreational\n",
    "\n",
    "Comment: {3}\n",
    "Theme: electronics\n",
    "\n",
    "Comment: {4}\n",
    "Theme:\n",
    "\"\"\".format(dataset['train']['text'][0].strip(),\n",
    "           dataset['train']['text'][4].strip(),\n",
    "           dataset['train']['text'][8].strip(),\n",
    "           dataset['train']['text'][10].strip(),\n",
    "           dataset['test']['text'][50].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d11a9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "What topic describes the following comment:\n",
    "{0}\n",
    "\"\"\".format(dataset['test']['text'][50].strip()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a71f939c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What topic describes the following comment:\\nOur experience not so great.  We have mortgage as well as basic free checking and savings with Dollar in Squirrel Hill.  Mortgage application process was brutal.  Starting with the advertised rate of 2.85% being suddenly not available when we decided to lock it in; got 3.01%.  Automatic deduction of mortgage payment was required to secure this rate and it came out of the required Dollar checking account on the first business day of the month.  Free checking is free ... until.  Beware of Funds Availability policy.  We deposit a check monthly at the end of the month.  In August, the end of the month was a weekend and Labor Day was on September 1.  So our check did not get deposited until 9/2.  Mortgage payment hit on 9/2. It was paid, but we were charged $36 insufficient funds due solely to Funds Availability Policy.  After doing this first, Dollar then merrily hits us with two more $36 charges on smaller checks that would have cleared had they been processed before the mortgage payment.  Had we NOT been required to submit to automatic deduction of mortgage, according to our monthly statement, we had at least 10 days grace to make the payment, so Dollar\\'s requirements and policies trapped us into this situation.  Moreover, there was over $3000 in the associated savings account that was ignored.  I called to protest, and one of the $36 fees was waived.  Then I was offered the \\\\\"\"deal\\\\\"\" of overdraft protection from the savings account for an annual fee plus a $10 transaction fee should this situation ever arise again.  Needless to say, I declined this deal and transferred the savings to the checking account where it sits until I find another bank and then fire Dollar.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffc98348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What topic describes the following comment:\n",
      "Our experience not so great.  We have mortgage as well as basic free checking and savings with Dollar in Squirrel Hill.  Mortgage application process was brutal.  Starting with the advertised rate of 2.85% being suddenly not available when we decided to lock it in; got 3.01%.  Automatic deduction of mortgage payment was required to secure this rate and it came out of the required Dollar checking account on the first business day of the month.  Free checking is free ... until.  Beware of Funds Availability policy.  We deposit a check monthly at the end of the month.  In August, the end of the month was a weekend and Labor Day was on September 1.  So our check did not get deposited until 9/2.  Mortgage payment hit on 9/2. It was paid, but we were charged $36 insufficient funds due solely to Funds Availability Policy.  After doing this first, Dollar then merrily hits us with two more $36 charges on smaller checks that would have cleared had they been processed before the mortgage payment.  Had we NOT been required to submit to automatic deduction of mortgage, according to our monthly statement, we had at least 10 days grace to make the payment, so Dollar's requirements and policies trapped us into this situation.  Moreover, there was over $3000 in the associated savings account that was ignored.  I called to protest, and one of the $36 fees was waived.  Then I was offered the \\\"\"deal\\\"\" of overdraft protection from the savings account for an annual fee plus a $10 transaction fee should this situation ever arise again.  Needless to say, I declined this deal and transferred the savings to the checking account where it sits until I find another bank and then fire Dollar.uerteipper reasoning\n",
      "CPU times: total: 3min 21s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "input_ids = mistral_tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "with torch.no_grad():\n",
    "    generated_ids = mistral_model.generate(input_ids, \n",
    "                                      do_sample=True,\n",
    "                                      temperature=0.1,\n",
    "                                      top_k=10,\n",
    "                                      top_p=10,\n",
    "                                      max_new_tokens=3)\n",
    "    generated_text = mistral_tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc3f851",
   "metadata": {},
   "source": [
    "Entering the prompt into ChatGPT, the performance is much better. Theme=customer service/banking/finance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91503010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMpy38",
   "language": "python",
   "name": "llmpy38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
